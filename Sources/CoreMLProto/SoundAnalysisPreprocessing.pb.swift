// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: SoundAnalysisPreprocessing.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright (c) 2019, Apple Inc. All rights reserved.
//
// Use of this source code is governed by a BSD-3-clause license that can be
// found in LICENSE.txt or at https://opensource.org/licenses/BSD-3-Clause

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

///
/// A model which takes audio signal samples as input and outputs an array of
/// preprocessed samples according to the specified preprocessing types
public struct CoreMLModels_SoundAnalysisPreprocessing: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Vision feature print type
  public var soundAnalysisPreprocessingType: CoreMLModels_SoundAnalysisPreprocessing.OneOf_SoundAnalysisPreprocessingType? = nil

  public var vggish: CoreMLModels_SoundAnalysisPreprocessing.Vggish {
    get {
      if case .vggish(let v)? = soundAnalysisPreprocessingType {return v}
      return CoreMLModels_SoundAnalysisPreprocessing.Vggish()
    }
    set {soundAnalysisPreprocessingType = .vggish(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Vision feature print type
  public enum OneOf_SoundAnalysisPreprocessingType: Equatable, Sendable {
    case vggish(CoreMLModels_SoundAnalysisPreprocessing.Vggish)

  }

  /// no specific parameter
  public struct Vggish: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "CoreML.Specification.CoreMLModels"

extension CoreMLModels_SoundAnalysisPreprocessing: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SoundAnalysisPreprocessing"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    20: .same(proto: "vggish"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 20: try {
        var v: CoreMLModels_SoundAnalysisPreprocessing.Vggish?
        var hadOneofValue = false
        if let current = self.soundAnalysisPreprocessingType {
          hadOneofValue = true
          if case .vggish(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.soundAnalysisPreprocessingType = .vggish(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if case .vggish(let v)? = self.soundAnalysisPreprocessingType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: CoreMLModels_SoundAnalysisPreprocessing, rhs: CoreMLModels_SoundAnalysisPreprocessing) -> Bool {
    if lhs.soundAnalysisPreprocessingType != rhs.soundAnalysisPreprocessingType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension CoreMLModels_SoundAnalysisPreprocessing.Vggish: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = CoreMLModels_SoundAnalysisPreprocessing.protoMessageName + ".Vggish"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: CoreMLModels_SoundAnalysisPreprocessing.Vggish, rhs: CoreMLModels_SoundAnalysisPreprocessing.Vggish) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
